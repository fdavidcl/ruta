url: "http://ruta.software"

template:
  params:
    bootswatch: lumen

authors:
  David Charte:
    href: http://david.quotient.space

navbar:
  title: Ruta
  type: default
  left:
    - text: "Home"
      href: ""
      icon: fa-home
    - text: "Get started"
      href: "articles/examples/autoencoder_basic.html"
      icon: fa-code
    - text: "Examples"
      menu:
        - text: "Building neural architectures"
          href: "articles/architectures.html"
        - text: "-----------------------------"
        - text: "Autoencoder variants"
        - text: "Contractive autoencoder"
          href: "articles/examples/autoencoder_contractive.html"
        - text: "Denoising autoencoder"
          href: "articles/examples/autoencoder_denoising.html"
        - text: "Robust autoencoder"
          href: "articles/examples/autoencoder_robust.html"
        - text: "Sparse autoencoder"
          href: "articles/examples/autoencoder_sparse.html"
        - text: "Variational autoencoder"
          href: "articles/examples/autoencoder_variational.html"
        - text: "Convolutional autoencoder"
          href: "articles/examples/autoencoder_convolutional.html"
    - text: "Troubleshooting"
      href: "articles/troubleshooting.html"
      icon: fa-wrench
  right:
    - text: "Documentation"
      icon: fa-book
      href: "reference/"
    - icon: fa-github
      href: "https://github.com/fdavidcl/ruta"

reference:
  - title: "Neural network architecture"
    desc: >
      This set of functions provide the necessary functionality to define the
      neural architectures of autoencoders, by connecting layers of units.
    contents:
      - input
      - dense
      - variational_block
      - conv
      - output
      - dropout
      - layer_keras
      - "c.ruta_network"
      - "[.ruta_network"
      - "plot.ruta_network"
      - new_layer
      - new_network
      - as_network
      - encoding_index
  - title: "Autoencoder and variants"
    desc: >
      These functions allow to create and customize autoencoder learners.
    contents:
      - autoencoder
      - starts_with("autoencoder_")
      - add_weight_decay
      - weight_decay
      - starts_with("make_")
      - is_contractive
      - is_denoising
      - is_robust
      - is_sparse
      - is_variational
      - sparsity
      - new_autoencoder
  - title: "Loss functions"
    desc: >
      These functions define different objective functions which an autoencoder
      may optimize. Along with these, one may use any loss defined in Keras (such
      as `"binary_crossentropy"` or `"mean_squared_error"`).
    contents:
      - contraction
      - correntropy
      - loss_variational
      - as_loss
  - title: "Model training"
    desc: >
      The following functions allow to train an autoencoder with input data.
    contents:
      - autoencode
      - starts_with("apply_filter")
      - train.ruta_autoencoder
      - is_trained
  - title: "Model evaluation"
    desc: >
      Evaluation metrics for trained models.
    contents:
      - starts_with("evaluate")
      - evaluation_metric
  - title: "Tasks for trained models"
    desc: >
      The following functions can be applied when an autoencoder has been
      trained, in order to transform data from the input space onto the latent
      space and viceversa.
    contents:
      - encode
      - decode
      - reconstruct
      - starts_with("generate")
      - save_as
  - title: "Noise generators"
    desc: >
      These objects act as input filters which generate some noise into the
      training inputs when fitting denoising autoencoders.
    contents:
      - starts_with("noise")
  - title: "Keras conversions"
    desc: >
      These are internal functions which convert Ruta wrapper objects into
      Keras objects and functions.
    contents:
      - starts_with("to_keras")
  - title: "Other methods"
    desc: >
      Some methods for R generics.
    contents:
      - starts_with("print.")
